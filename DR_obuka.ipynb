{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DR_obuka.ipynb","provenance":[{"file_id":"1QSexfqijZ7nzlLg0NE3QEyKyS-SSvkLj","timestamp":1575920647272}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"aZNBtegtGKJW","executionInfo":{"status":"ok","timestamp":1575919825431,"user_tz":-60,"elapsed":20547,"user":{"displayName":"Boris Papić","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDrPMpc5G-upJfZVwOW2wX2Y4REaR8sRonx08zmmw8=s64","userId":"05712926183957447644"}},"outputId":"ae8011f6-4143-403a-eb94-d9e188302639","colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","#drive.mount(\"/content/drive\", force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ayV3lUOXGQLe"},"source":["%%capture\n","!pip install --upgrade tensorflow\n","!pip show tensorflow"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JhkUpEysGRbP"},"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import os\n","import csv\n","import re\n","import cv2\n","from tensorflow.keras import losses\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.utils import Sequence\n","from tensorflow.keras.losses import Huber\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error as mse_met\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n","                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D)\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from sklearn.utils import shuffle\n","from sklearn.metrics import cohen_kappa_score\n","from tensorflow.keras import metrics\n","from tensorflow.keras.optimizers import Adam\n","import tensorflow.keras\n","from tensorflow.python.keras import backend as k\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.callbacks import (ModelCheckpoint,Callback,LearningRateScheduler,EarlyStopping,ReduceLROnPlateau,CSVLogger)\n","from imgaug import augmenters as iaa\n","import imgaug as ia\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","CLASSS = {0: \"No DR\", 1: \"Mild\", 2: \"Moderate\", 3: \"Severe\", 4: \"Proliferative DR\"}\n","\n","# ovde zameni path sa svojim path u blindness Challenge folder, glavni folder\n","dest_only_2019 = \"/content/drive/My Drive/Colab Notebooks/BlindnessChallenge\"\n","\n","IMG_SIZE = 512\n","EPOCHS = 30\n","batch_size = 4\n","CLASS_ID = 4\n","WORKERS = 2\n","# i ovde kod checkpoint obavezno zameni path samo da bude tvoj_path/working/nevena_ep_512_{epoch:02d}.hdf5\n","checkpoint = ModelCheckpoint(filepath=\"/content/drive/My Drive/Colab Notebooks/BlindnessChallenge/working/nevena_ep_512_{epoch:02d}.hdf5\", monitor=\"val_loss\", verbose=1,\n","                             save_best_only=False, mode='min', save_weights_only=False)\n","reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, verbose=1, mode='auto',\n","                                   min_delta=0.0001)\n","early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=9)\n","csv_logger = CSVLogger(filename=f'{dest_only_2019}/working/nevena_training_log_512.csv', separator=',', append=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"saj306eBHopd"},"source":["def loadDatasets(dest):\n","    df_train_2019 = pd.read_csv(f\"{dest}/trainLabels19.csv\")\n","    df_train_2015 = pd.read_csv(f\"{dest}/trainLabels15.csv\")\n","    df_train_2015.columns = df_train_2019.columns\n","    #print(df_train_2015.head())\n","    df_train = pd.concat([df_train_2015,df_train_2019],axis=0)\n","    x,y = shuffle(df_train['id_code'],df_train['diagnosis'],random_state=42)\n","    #y = to_categorical(y, num_classes=5)\n","    #x_val,y = shuffle(df_test['id_code'],df_test['diagnosis'],random_state=42)\n","    #y_val = to_categorical(y, num_classes=5)\n","    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.15,\n","                                                      stratify=y, random_state=42)\n","    return x_train, x_val, y_train, y_val\n","\n","def loadDatasets_only_2019(dest_only_2019):\n","    df_train = pd.read_csv(f\"{dest_only_2019}/train.csv\")\n","    train_aug = pd.read_csv(f\"{dest_only_2019}/augmentacije.csv\")\n","    train_aug.drop(train_aug.columns[0],axis=1,inplace=True)\n","    train_aug.index = [i for i in range(3662,3662+838)]\n","    train_aug.columns = ['id_code','diagnosis']\n","\n","    df_train = pd.concat([df_train,train_aug])\n","    #print(df_train.sample)\n","    x,y = shuffle(df_train['id_code'],df_train['diagnosis'],random_state=42)\n","    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.15,\n","                                                      stratify=y, random_state=42)\n","    return x_train, x_val, y_train, y_val\n","    \n","x_train, x_val, y_train, y_val = loadDatasets_only_2019(dest_only_2019)\n","#train_aug = pd.read_csv(f\"{dest_only_2019}/augmentacije.csv\")\n","#x_train = pd.concat([x_train,train_aug['0']])\n","#y_train = pd.concat([y_train,train_aug['1']])\n","y_train = to_categorical(y_train, num_classes=5)\n","y_val = to_categorical(y_val, num_classes=5)\n","\n","\n","#preprocessing\n","#mean=(0,485, 0,456, 0,406) and std=(0,229, 0,224, 0,225)\n","def normalization_fn(img):\n","    img = np.divide(img,255)\n","    mean_value  = [0.485,0.456,0.406]\n","    std_value = [0.229,0.224,0.225]\n","    std_after = []\n","    mean_after = []\n","    for i in range(3):\n","        norm_tmp = np.subtract(img[:,:,i],np.mean(img[:,:,i]))\n","        std_mult = np.divide(std_value[i],np.std(img[:,:,i], dtype=np.float64))\n","        img[:,:,i] = np.add(mean_value[i],np.multiply(norm_tmp,std_mult))\n","        #mean_after.append(np.mean(img[:,:,i]))\n","        #std_after.append(np.std(img[:,:,i]))\n","    return img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"InhE6SxnH_8W"},"source":["def bens_processing_plot(df_train,dest,IMG_SIZE):\n","    sigmaX = 50\n","    fig,ax = plt.subplots(2, 6, figsize=(15, 6))\n","    df_tmp = df_train.sample(12)\n","    for idxn,(id,row) in enumerate(df_tmp.iteritems()):\n","        #print(row)\n","        path= f\"{dest}/train_images/{row}.png\"\n","        # image = cv2.imread(path)\n","        # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        # image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n","        # image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , IMG_SIZE/10) ,-4 ,128)\n","        image = cv2.imread(path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        #image = crop_image_from_gray(image)\n","        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n","        img=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n","        #privremeno da vidim kako radi seq_boris i konstruisem svoj filter, kasnije obrisati ili zakomentarisati\n","        #img = seq.augment_image(img)\n","\n","        row = idxn // 6\n","        col = idxn % 6\n","        ax[row,col].imshow(img)\n","    #plt.show()\n","    #return image\n","def bens_processing(img,IMG_SIZE):\n","    sigma = 50\n","    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","    image = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n","    image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigma) ,-4 ,128)\n","    return image\n","\n","    \n","sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n","seq_boris = iaa.Sequential(\n","    [\n","        iaa.Fliplr(0.5), # horizontally flip 50% of all images\n","        iaa.Flipud(0.2),\n","        sometimes(iaa.Affine(\n","                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}, # scale images to 80-120% of their size, individually per axis\n","                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, # translate by -20 to +20 percent (per axis)\n","                rotate=(-10, 10), # rotate by -45 to +45 degrees\n","                shear=(-5, 5), # shear by -16 to +16 degrees\n","                order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n","                cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n","                mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n","            )),\n","        iaa.SomeOf((0, 4),\n","                [\n","                    sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(10, 50))), # convert images into their superpixel representation\n","                    iaa.OneOf([\n","                        iaa.GaussianBlur((0, 1.0)), # blur images with a sigma between 0 and 3.0\n","                        iaa.AverageBlur(k=(3, 5)), # blur image using local means with kernel sizes between 2 and 7\n","                        iaa.MedianBlur(k=(3, 5)), # blur image using local medians with kernel sizes between 2 and 7\n","                    ]),\n","                    iaa.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)), # sharpen images\n","                    iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n","                    # search either for all edges or for directed edges,\n","                    # blend the result with the original image using a blobby mask\n","                    iaa.SimplexNoiseAlpha(iaa.OneOf([\n","                        iaa.EdgeDetect(alpha=(0.5, 1.0)),\n","                        iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n","                    ])),\n","                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.5), # add gaussian noise to images\n","                    iaa.OneOf([\n","                        iaa.Dropout((0.01, 0.05), per_channel=0.5), # randomly remove up to 10% of the pixels\n","                        iaa.CoarseDropout((0.01, 0.03), size_percent=(0.01, 0.02), per_channel=0.2),\n","                    ]),\n","                    iaa.Invert(0.01, per_channel=True), # invert color channels\n","                    iaa.Add((-2, 2), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n","                    iaa.AddToHueAndSaturation((-1, 1)), # change hue and saturation\n","                    # either change the brightness of the whole image (sometimes\n","                    # per channel) or change the brightness of subareas\n","                    iaa.OneOf([\n","                        iaa.Multiply((0.9, 1.1), per_channel=0.5),\n","                        iaa.FrequencyNoiseAlpha(\n","                            exponent=(-1, 0),\n","                            first=iaa.Multiply((0.9, 1.1), per_channel=True),\n","                            second=iaa.ContrastNormalization((0.9, 1.1))\n","                        )\n","                    ])\n","                ],\n","                random_order=True\n","            )\n","        \n","        \n","    ],random_order=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pe_cxWhEIP3Y","executionInfo":{"status":"ok","timestamp":1575919963677,"user_tz":-60,"elapsed":5648,"user":{"displayName":"Boris Papić","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDrPMpc5G-upJfZVwOW2wX2Y4REaR8sRonx08zmmw8=s64","userId":"05712926183957447644"}},"outputId":"e852a0fc-20cc-4fbb-be8a-85658804f1db","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["def create_model(input_shape, n_out,dest):\n","    input_tensor = Input(shape=input_shape)\n","    base_model = ResNet50(include_top=False,\n","                   weights='imagenet',\n","                   input_tensor=input_tensor)\n","    #base_model=load_model(\"/content/drive/My Drive/Colab Notebooks/BlindnessChallenge/efficient_net/working/weights_ep0_batch_1950.h5\")\n","    #model = base_model\n","    x = GlobalAveragePooling2D()(base_model.output)\n","    x = Dropout(0.5)(x)\n","    x = Dense(1024, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    final_output = Dense(5, name='final_output')(x)\n","    model = Model(input_tensor, final_output)\n","    return model\n","\n","model = create_model(\n","        input_shape=(IMG_SIZE,IMG_SIZE, 3),\n","        n_out=5,dest=dest_only_2019)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94773248/94765736 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YXj8JcDaIStT"},"source":["class My_Generator(Sequence):\n","    def __init__(self,image_filenames,labels,dest,\n","            batch_size,is_train=True,\n","            mix=False,augment=False,IMG_size=512):\n","        self.image_filenames,self.labels = image_filenames,labels\n","        self.batch_size = batch_size\n","        self.IMG_size = IMG_size\n","        self.dest = dest\n","        self.is_train = is_train\n","        self.is_augment = augment\n","        if(self.is_train):\n","            self.on_epoch_end()\n","        self.is_mix = mix\n","        \n","    def __len__(self):\n","        return int(np.ceil(len(self.image_filenames)/float(self.batch_size)))\n","    \n","    def __getitem__(self,idx):\n","        batch_x = self.image_filenames[idx*self.batch_size:(idx+1)*self.batch_size]\n","        batch_y = self.labels[idx*self.batch_size:(idx+1)*self.batch_size]\n","        \n","        if(self.is_train):\n","            return self.train_generate(batch_x,batch_y)\n","        return self.valid_generate(batch_x,batch_y)\n","        \n","    def on_epoch_end(self):\n","        if(self.is_train):\n","            self.image_filenames,self.labels = shuffle(self.image_filenames,self.labels)\n","        else:\n","            pass\n","    \n","    def mix_up(self,x,y):\n","        lam = np.random.beta(0.2,0.4)\n","        ori_index = np.arange(int(len(x)))\n","        index_array = np.arange(int(len(x)))\n","        np.random.shuffle(index_array)\n","        \n","        mixed_x = lam*x[ori_index] + (1-lam)*x[index_array]\n","        mixed_y = lam*y[ori_index] + (1-lam)*y[index_array]\n","        \n","        return mixed_x, mixed_y\n","\n","    def train_generate(self,batch_x,batch_y):\n","        batch_images = []\n","        for (sample,label) in zip(batch_x,batch_y):\n","            if \"augmented\" in str(sample): \n","                path=f\"{dest_only_2019}/train_images_augmented/{sample}.png\"\n","            else:\n","                path=f\"{dest_only_2019}/train_images/{sample}.png\"\n","            img = cv2.imread(path)\n","            img = bens_processing(img,self.IMG_size)\n","            img = cv2.resize(img,(self.IMG_size,self.IMG_size))\n","            if(self.is_augment):\n","                img = seq_boris.augment_image(img)\n","            img = normalization_fn(img)\n","            batch_images.append(img)\n","        batch_images = np.array(batch_images,np.float32)/255\n","        batch_y = np.array(batch_y,np.float32)\n","        if(self.is_mix):\n","            batch_images, batch_y = self.mix_up(batch_images, batch_y)\n","        return batch_images, batch_y\n","        \n","    def valid_generate(self, batch_x, batch_y):\n","        batch_images =[]\n","        for (sample,label) in zip(batch_x,batch_y):\n","            #print(sample)\n","            if \"augmented\" in str(sample): \n","                path=f\"{dest_only_2019}/train_images_augmented/{sample}.png\"\n","            else:\n","                path=f\"{dest_only_2019}/train_images/{sample}.png\"\n","            img = cv2.imread(path)\n","            img = bens_processing(img,self.IMG_size)\n","            img = cv2.resize(img,(self.IMG_size,self.IMG_size))\n","            img = normalization_fn(img)\n","            batch_images.append(img)\n","        batch_images = np.array(batch_images, np.float32) / 255\n","        batch_y = np.array(batch_y, np.float32)\n","        return batch_images, batch_y\n","    \n","train_generator = My_Generator(x_train, y_train,dest_only_2019, batch_size, is_train=True)\n","train_mixup = My_Generator(x_train, y_train, dest_only_2019,batch_size, is_train=True, mix=False, augment=False)\n","valid_generator = My_Generator(x_val, y_val, dest_only_2019,batch_size, is_train=False)\n","\n","def flatten_fn(y):\n","    for i in range(len(y)):\n","        if y[i] < 0.7:\n","            y[i] = 0\n","        elif y[i]> 0.7 and y[i]<1.5:\n","            y[i] = 1\n","        elif y[i]> 1.5 and y[i]< 2.5:\n","            y[i] = 2\n","        elif y[i] >2.5 and y[i]<3.5:\n","            y[i] = 3\n","        elif y[i]> 3.5:\n","            y[i] = 4\n","    return y\n","\n","\n","class QWKEvaluation(Callback):\n","    def __init__(self,validation_data=(),batch_size=32,interval=1):\n","        super(Callback,self).__init__()\n","        \n","        self.interval = interval\n","        self.batch_size = batch_size\n","        self.valid_generator, self.y_val = validation_data\n","        self.history = []\n","        self.batch_n = 100\n","    def on_epoch_begin(self,epoch,logs={}):\n","        #print(f'starting epoch: {epoch}')\n","        self.epoch = epoch\n","    #def on_batch_end(self, batch, logs={}):\n","    #    if batch % self.batch_n == 500 and batch > 1:\n","    #        name = f'/content/drive/My Drive/Colab Notebooks/BlindnessChallenge/working/nevena_weights_ep{self.epoch}_batch_{batch}.h5'\n","    #        self.model.save(name)\n","    '''\n","    def on_train_batch_begin(self,batch, logs=None):\n","        self.start_time = time.time()\n","    def on_train_batch_end(self,batch, logs=None):\n","        self.end_time = time.time()\n","        print(self.end_time - self.start_time)'''\n","        \n","    def on_epoch_end(self, epoch, logs={}):\n","        if epoch % self.interval == 0:\n","            y_pred = self.model.predict_generator(generator=self.valid_generator, steps=np.ceil(float(len(self.y_val))/float(self.batch_size)),workers=1,use_multiprocessing=False,verbose=1)\n","            def flatten_class(y):\n","                return np.argmax(y, axis=1).reshape(-1)\n","            #y_tmp = self.y_val.to_numpy()\n","\n","            score = cohen_kappa_score(flatten_class(y_val), flatten_class(y_pred), labels = [0,1,2,3,4],weights='quadratic')\n","            print(f\"\\n epoch: {epoch+1} - QWK_score: {score}\")\n","            self.history.append(score)\n","            if score >= max(self.history):\n","                print(f\"saving checkpoint:{score}\")\n","                self.model.save(\"/content/drive/My Drive/Colab Notebooks/BlindnessChallenge/working/nevena_best_qwk.h5\")\n","                \n","qwk = QWKEvaluation(validation_data=(valid_generator, y_val), batch_size=batch_size, interval=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1HhHyMWcIsVG","executionInfo":{"status":"error","timestamp":1575920641331,"user_tz":-60,"elapsed":393188,"user":{"displayName":"Boris Papić","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDrPMpc5G-upJfZVwOW2wX2Y4REaR8sRonx08zmmw8=s64","userId":"05712926183957447644"}},"outputId":"0c516903-4c66-4344-db68-83e7c76d7e34","colab":{"base_uri":"https://localhost:8080/","height":867}},"source":["#i ovde obavezno zameni path kod checkpoint warm_up\n","checkpoint_warm_up = ModelCheckpoint(filepath=\"/content/drive/My Drive/Colab Notebooks/BlindnessChallenge/working/nevena_ep_512_warm_up_{epoch:02d}.hdf5\", monitor=\"val_loss\", verbose=1,\n","                             save_best_only=False, mode='min', save_weights_only=False)\n","for layer in model.layers:\n","    layer.trainable = False\n","\n","for i in range(-3, 0):\n","    model.layers[i].trainable = True\n","\n","model.compile(\n","    loss= 'categorical_crossentropy',\n","    optimizer=Adam(1e-3))\n","\n","model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=np.ceil(float(len(y_train)) / float(batch_size)),\n","    epochs=2,\n","    workers=WORKERS, use_multiprocessing=True,\n","    verbose=1,\n","    callbacks=[qwk,checkpoint_warm_up])#moze true multiprocessing np.ceil(float(len(y_train)) / float(batch_size))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n"," 18/988 [..............................] - ETA: 5:42:48 - loss: 3.3059"],"name":"stdout"},{"output_type":"stream","text":["Process Keras_worker_ForkPoolWorker-12:\n","Process Keras_worker_ForkPoolWorker-11:\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n","    task = get()\n","  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n","    task = get()\n","  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n","    res = self._reader.recv_bytes()\n","  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n","    with self._rlock:\n","  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n","    return self._semlock.__enter__()\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","KeyboardInterrupt\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-2b365f095c61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWORKERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     callbacks=[qwk,checkpoint_warm_up])#moze true multiprocessing np.ceil(float(len(y_train)) / float(batch_size))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m           \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_FusedBatchNormV3Grad\u001b[0;34m(op, *grad)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FusedBatchNormV3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_FusedBatchNormV3Grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_BaseFusedBatchNormGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_BaseFusedBatchNormGrad\u001b[0;34m(op, version, *grad)\u001b[0m\n\u001b[1;32m    888\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reserve_space_3\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    891\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0mpop_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mfused_batch_norm_grad_v3\u001b[0;34m(y_backprop, x, scale, reserve_space_1, reserve_space_2, reserve_space_3, epsilon, data_format, is_training, name)\u001b[0m\n\u001b[1;32m   4325\u001b[0m         \u001b[0my_backprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreserve_space_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreserve_space_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4326\u001b[0m         \u001b[0mreserve_space_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"epsilon\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4327\u001b[0;31m         \"is_training\", is_training)\n\u001b[0m\u001b[1;32m   4328\u001b[0m       \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FusedBatchNormGradV3Output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4329\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"1PoL2g1JJCqx"},"source":["\n","# ovde load model kad zavrsis dve epohe warm upa koje si radila ili kada ti tokom ove normalne obuke pukne na nekoj epohi recimo load model nevena_ep_13 ako ti je pukao na 14toj epohi i stavis onda initial epoch 13\n","# kad pocinjes nakon zavrsenog warm up onda idi load_model nevena_ep_512_warm_up_02.hdf5\n","callbacks_list = [checkpoint, reduceLROnPlat, early, qwk,csv_logger]\n","for layer in model.layers:\n","        layer.trainable = True\n","\n","model.compile(loss='categorical_crossentropy',\n","              # loss=kappa_loss,\n","              optimizer=Adam(lr=1e-4))\n","model.fit_generator(\n","    train_mixup,\n","    steps_per_epoch=int(np.ceil(float(len(x_train)) / float(batch_size))),\n","    validation_data=valid_generator,\n","    validation_steps=int(np.ceil(float(len(x_val)) / float(batch_size))),\n","    epochs=30,\n","    verbose=1,max_queue_size=1,\n","    workers=1, use_multiprocessing=False,\n","    callbacks=callbacks_list,initial_epoch=0)\n"],"execution_count":null,"outputs":[]}]}